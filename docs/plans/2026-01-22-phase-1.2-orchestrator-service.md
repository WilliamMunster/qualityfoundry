# Phase 1.2 OrchestratorService Implementation Plan

> **For Claude:** REQUIRED SUB-SKILL: Use superpowers:executing-plans to implement this plan task-by-task.

**Goal:** Extract business logic from `routes_orchestrations.py` into a testable, reusable `OrchestratorService` with LangGraph-ready node boundaries.

**Architecture:** Service receives `OrchestrationRequest`, normalizes to internal state, executes 5 node-boundary methods (load_policy â†’ plan â†’ execute â†’ collect â†’ gate), returns domain object `OrchestrationResult`. Route layer handles HTTP concerns (URL construction, response assembly).

**Tech Stack:** Python 3.11+, FastAPI, Pydantic, dataclasses, pytest, pytest-asyncio

---

## Task 1: Define Domain Types

**Files:**
- Create: `backend/app/qualityfoundry/services/orchestrator_service.py`

**Step 1: Write the type definitions**

```python
"""QualityFoundry - Orchestrator Service (L2 Orchestration Layer)

Phase 1.2: Service abstraction with LangGraph-ready node boundaries.

Design decisions:
- Dependency injection: DB required, registry/collector/policy optional (testable)
- Return type: OrchestrationResult (domain object, no HTTP concepts)
- Input: OrchestrationRequest (API DTO) + internal normalization
- Node methods: _load_policy, _plan_tool_request, _execute_tools, _collect_evidence, _gate_and_hitl
"""

from __future__ import annotations

from dataclasses import dataclass, field
from pathlib import Path
from typing import Any, Callable, TypedDict
from uuid import UUID

from qualityfoundry.governance import GateDecision
from qualityfoundry.governance.policy_loader import PolicyConfig
from qualityfoundry.tools.contracts import ToolRequest, ToolResult


@dataclass(frozen=True)
class OrchestrationInput:
    """Internal normalized input (decoupled from API DTO)."""
    nl_input: str
    environment_id: UUID | None
    tool_name: str
    tool_args: dict[str, Any]
    timeout_s: int
    dry_run: bool


@dataclass(frozen=True)
class OrchestrationResult:
    """Service return type (domain object, no HTTP concepts)."""
    run_id: UUID
    decision: GateDecision
    reason: str
    evidence: dict[str, Any]
    execution_id: UUID | None = None
    approval_id: UUID | None = None
    report_path: Path | None = None


class OrchestrationState(TypedDict, total=False):
    """Mutable state passed through node methods (LangGraph-ready)."""
    run_id: UUID
    input: OrchestrationInput
    policy: PolicyConfig
    policy_meta: dict[str, Any]
    tool_request: ToolRequest
    tool_result: ToolResult
    evidence: dict[str, Any]
    decision: GateDecision
    reason: str
    approval_id: UUID | None
    report_path: Path | None
```

**Step 2: Verify file syntax**

Run: `python -c "from qualityfoundry.services.orchestrator_service import OrchestrationResult, OrchestrationState, OrchestrationInput"`
Expected: No errors

**Step 3: Commit**

```bash
git add backend/app/qualityfoundry/services/orchestrator_service.py
git commit -m "feat(orchestrator): add domain types for Phase 1.2

- OrchestrationInput: normalized internal input
- OrchestrationResult: domain return object (no HTTP concepts)
- OrchestrationState: LangGraph-ready state TypedDict"
```

---

## Task 2: Implement OrchestratorService Skeleton

**Files:**
- Modify: `backend/app/qualityfoundry/services/orchestrator_service.py`

**Step 1: Write the service class skeleton**

Add after the type definitions:

```python
from sqlalchemy.orm import Session

from qualityfoundry.api.v1.routes_orchestrations import OrchestrationRequest, OrchestrationOptions
from qualityfoundry.governance.policy_loader import get_policy, PolicyConfig
from qualityfoundry.governance.tracing.collector import TraceCollector
from qualityfoundry.services.approval_service import ApprovalService
from qualityfoundry.tools.registry import get_registry, ToolRegistry


# Type alias for collector factory (testability)
CollectorFactory = Callable[[UUID, str, dict[str, Any]], TraceCollector]


def _default_collector_factory(run_id: UUID, input_nl: str, environment: dict[str, Any]) -> TraceCollector:
    """Default factory creates real TraceCollector."""
    return TraceCollector(run_id=str(run_id), input_nl=input_nl, environment=environment)


class OrchestratorService:
    """Orchestration service with LangGraph-ready node boundaries.

    Dependency injection:
    - db: Required (for ApprovalService)
    - registry: Optional (default: global singleton)
    - collector_factory: Optional (default: creates real TraceCollector)
    - policy_loader: Optional (default: loads from file)
    """

    def __init__(
        self,
        db: Session,
        *,
        registry: ToolRegistry | None = None,
        collector_factory: CollectorFactory | None = None,
        policy_loader: Callable[[], PolicyConfig] | None = None,
    ):
        self._db = db
        self._registry = registry
        self._collector_factory = collector_factory or _default_collector_factory
        self._policy_loader = policy_loader or get_policy
        self._approval_service = ApprovalService(db)

    @property
    def registry(self) -> ToolRegistry:
        """Lazy registry access (allows late binding for tests)."""
        return self._registry or get_registry()

    async def run(self, req: OrchestrationRequest) -> OrchestrationResult:
        """Execute orchestration pipeline.

        Pipeline: normalize â†’ load_policy â†’ plan â†’ execute â†’ collect â†’ gate
        """
        raise NotImplementedError("Task 3 will implement this")

    def _normalize_input(self, req: OrchestrationRequest) -> OrchestrationInput:
        """Convert API DTO to internal normalized input."""
        raise NotImplementedError("Task 3 will implement this")

    def _load_policy(self, state: OrchestrationState) -> OrchestrationState:
        """Node 1: Load policy configuration."""
        raise NotImplementedError("Task 4 will implement this")

    def _plan_tool_request(self, state: OrchestrationState) -> OrchestrationState:
        """Node 2: Build tool request from input."""
        raise NotImplementedError("Task 4 will implement this")

    async def _execute_tools(self, state: OrchestrationState) -> OrchestrationState:
        """Node 3: Execute tool and collect result."""
        raise NotImplementedError("Task 5 will implement this")

    def _collect_evidence(self, state: OrchestrationState) -> OrchestrationState:
        """Node 4: Collect evidence and save to disk."""
        raise NotImplementedError("Task 5 will implement this")

    def _gate_and_hitl(self, state: OrchestrationState) -> OrchestrationState:
        """Node 5: Evaluate gate and create approval if needed."""
        raise NotImplementedError("Task 6 will implement this")
```

**Step 2: Verify imports work**

Run: `python -c "from qualityfoundry.services.orchestrator_service import OrchestratorService"`
Expected: No errors

**Step 3: Commit**

```bash
git add backend/app/qualityfoundry/services/orchestrator_service.py
git commit -m "feat(orchestrator): add OrchestratorService skeleton

- Mixed dependency injection (DB required, others optional)
- 5 node-boundary method stubs (LangGraph-ready)
- CollectorFactory type for testability"
```

---

## Task 3: Implement run() and _normalize_input()

**Files:**
- Modify: `backend/app/qualityfoundry/services/orchestrator_service.py`

**Step 1: Write the failing test**

Create file `backend/tests/test_orchestrator_service.py`:

```python
"""Unit tests for OrchestratorService (Phase 1.2)."""

import pytest
from unittest.mock import MagicMock, AsyncMock
from uuid import uuid4

from qualityfoundry.api.v1.routes_orchestrations import OrchestrationRequest, OrchestrationOptions
from qualityfoundry.services.orchestrator_service import (
    OrchestratorService,
    OrchestrationInput,
)


class TestNormalizeInput:
    """Tests for _normalize_input method."""

    def test_normalize_with_options(self):
        """When options provided, use them directly."""
        db = MagicMock()
        service = OrchestratorService(db)

        req = OrchestrationRequest(
            nl_input="run tests",
            environment_id=None,
            options=OrchestrationOptions(
                tool_name="run_pytest",
                args={"test_path": "tests/unit"},
                timeout_s=60,
                dry_run=True,
            ),
        )

        result = service._normalize_input(req)

        assert isinstance(result, OrchestrationInput)
        assert result.nl_input == "run tests"
        assert result.tool_name == "run_pytest"
        assert result.tool_args == {"test_path": "tests/unit"}
        assert result.timeout_s == 60
        assert result.dry_run is True

    def test_normalize_without_options_defaults_to_pytest(self):
        """When no options, default to pytest with 'tests' path."""
        db = MagicMock()
        service = OrchestratorService(db)

        req = OrchestrationRequest(
            nl_input="run my tests please",
            environment_id=None,
            options=None,
        )

        result = service._normalize_input(req)

        assert result.tool_name == "run_pytest"
        assert result.tool_args == {"test_path": "tests"}
        assert result.timeout_s == 120
        assert result.dry_run is False

    def test_normalize_playwright_keyword(self):
        """When nl_input contains 'playwright', select playwright tool."""
        db = MagicMock()
        service = OrchestratorService(db)

        req = OrchestrationRequest(
            nl_input="run playwright e2e tests",
            environment_id=None,
            options=None,
        )

        result = service._normalize_input(req)

        assert result.tool_name == "run_playwright"
        assert result.timeout_s == 300
```

**Step 2: Run test to verify it fails**

Run: `cd backend && python -m pytest tests/test_orchestrator_service.py -v`
Expected: FAIL with NotImplementedError

**Step 3: Implement _normalize_input**

Replace the `_normalize_input` method:

```python
    def _normalize_input(self, req: OrchestrationRequest) -> OrchestrationInput:
        """Convert API DTO to internal normalized input."""
        if req.options:
            return OrchestrationInput(
                nl_input=req.nl_input,
                environment_id=req.environment_id,
                tool_name=req.options.tool_name,
                tool_args=req.options.args,
                timeout_s=req.options.timeout_s,
                dry_run=req.options.dry_run,
            )

        # Heuristic: choose tool based on nl_input keywords
        nl_lower = req.nl_input.lower()
        if "playwright" in nl_lower or "browser" in nl_lower or "e2e" in nl_lower:
            return OrchestrationInput(
                nl_input=req.nl_input,
                environment_id=req.environment_id,
                tool_name="run_playwright",
                tool_args={},
                timeout_s=300,
                dry_run=False,
            )

        # Default: pytest
        return OrchestrationInput(
            nl_input=req.nl_input,
            environment_id=req.environment_id,
            tool_name="run_pytest",
            tool_args={"test_path": "tests"},
            timeout_s=120,
            dry_run=False,
        )
```

**Step 4: Run test to verify it passes**

Run: `cd backend && python -m pytest tests/test_orchestrator_service.py::TestNormalizeInput -v`
Expected: PASS (3 tests)

**Step 5: Commit**

```bash
git add backend/app/qualityfoundry/services/orchestrator_service.py backend/tests/test_orchestrator_service.py
git commit -m "feat(orchestrator): implement _normalize_input with heuristics

- Options take precedence over heuristics
- Default to pytest with 'tests' path
- Detect playwright/browser/e2e keywords"
```

---

## Task 4: Implement _load_policy and _plan_tool_request

**Files:**
- Modify: `backend/app/qualityfoundry/services/orchestrator_service.py`
- Modify: `backend/tests/test_orchestrator_service.py`

**Step 1: Write the failing test for _load_policy**

Add to `test_orchestrator_service.py`:

```python
from qualityfoundry.governance.policy_loader import PolicyConfig
from qualityfoundry.services.orchestrator_service import OrchestrationState


class TestLoadPolicy:
    """Tests for _load_policy node."""

    def test_load_policy_adds_policy_to_state(self):
        """_load_policy should add policy and policy_meta to state."""
        db = MagicMock()
        fake_policy = PolicyConfig(version="test-1.0")
        service = OrchestratorService(db, policy_loader=lambda: fake_policy)

        state: OrchestrationState = {"run_id": uuid4()}

        result = service._load_policy(state)

        assert result["policy"] == fake_policy
        assert result["policy_meta"]["version"] == "test-1.0"
```

**Step 2: Run test to verify it fails**

Run: `cd backend && python -m pytest tests/test_orchestrator_service.py::TestLoadPolicy -v`
Expected: FAIL with NotImplementedError

**Step 3: Implement _load_policy**

Replace the method:

```python
    def _load_policy(self, state: OrchestrationState) -> OrchestrationState:
        """Node 1: Load policy configuration."""
        policy = self._policy_loader()
        state["policy"] = policy
        state["policy_meta"] = {
            "version": policy.version,
            "high_risk_keywords_count": len(policy.high_risk_keywords),
            "high_risk_patterns_count": len(policy.high_risk_patterns),
        }
        return state
```

**Step 4: Run test to verify it passes**

Run: `cd backend && python -m pytest tests/test_orchestrator_service.py::TestLoadPolicy -v`
Expected: PASS

**Step 5: Write the failing test for _plan_tool_request**

Add to `test_orchestrator_service.py`:

```python
from qualityfoundry.tools.contracts import ToolRequest


class TestPlanToolRequest:
    """Tests for _plan_tool_request node."""

    def test_plan_creates_tool_request(self):
        """_plan_tool_request should create ToolRequest from input."""
        db = MagicMock()
        service = OrchestratorService(db)

        run_id = uuid4()
        inp = OrchestrationInput(
            nl_input="run tests",
            environment_id=None,
            tool_name="run_pytest",
            tool_args={"test_path": "tests/unit"},
            timeout_s=60,
            dry_run=False,
        )
        state: OrchestrationState = {"run_id": run_id, "input": inp}

        result = service._plan_tool_request(state)

        assert "tool_request" in result
        tr = result["tool_request"]
        assert isinstance(tr, ToolRequest)
        assert tr.tool_name == "run_pytest"
        assert tr.args == {"test_path": "tests/unit"}
        assert tr.run_id == run_id
        assert tr.timeout_s == 60
        assert tr.dry_run is False
```

**Step 6: Run test to verify it fails**

Run: `cd backend && python -m pytest tests/test_orchestrator_service.py::TestPlanToolRequest -v`
Expected: FAIL with NotImplementedError

**Step 7: Implement _plan_tool_request**

Replace the method:

```python
    def _plan_tool_request(self, state: OrchestrationState) -> OrchestrationState:
        """Node 2: Build tool request from input."""
        inp = state["input"]
        state["tool_request"] = ToolRequest(
            tool_name=inp.tool_name,
            args=inp.tool_args,
            run_id=state["run_id"],
            timeout_s=inp.timeout_s,
            dry_run=inp.dry_run,
        )
        return state
```

**Step 8: Run test to verify it passes**

Run: `cd backend && python -m pytest tests/test_orchestrator_service.py::TestPlanToolRequest -v`
Expected: PASS

**Step 9: Commit**

```bash
git add backend/app/qualityfoundry/services/orchestrator_service.py backend/tests/test_orchestrator_service.py
git commit -m "feat(orchestrator): implement _load_policy and _plan_tool_request nodes

- _load_policy: loads policy via injected loader, records meta
- _plan_tool_request: creates ToolRequest from normalized input"
```

---

## Task 5: Implement _execute_tools and _collect_evidence

**Files:**
- Modify: `backend/app/qualityfoundry/services/orchestrator_service.py`
- Modify: `backend/tests/test_orchestrator_service.py`

**Step 1: Write the failing test for _execute_tools**

Add to `test_orchestrator_service.py`:

```python
from qualityfoundry.tools.contracts import ToolResult, ToolStatus
from qualityfoundry.tools.registry import ToolRegistry


class TestExecuteTools:
    """Tests for _execute_tools node."""

    @pytest.mark.asyncio
    async def test_execute_calls_registry(self):
        """_execute_tools should call registry.execute with tool_request."""
        db = MagicMock()

        # Create fake registry with mock tool
        fake_registry = ToolRegistry()
        fake_result = ToolResult(
            status=ToolStatus.SUCCESS,
            stdout="test output",
            stderr=None,
        )

        async def fake_tool(req):
            return fake_result

        fake_registry.register("run_pytest", fake_tool)

        service = OrchestratorService(db, registry=fake_registry)

        run_id = uuid4()
        tool_request = ToolRequest(
            tool_name="run_pytest",
            args={"test_path": "tests"},
            run_id=run_id,
            timeout_s=60,
        )
        state: OrchestrationState = {
            "run_id": run_id,
            "tool_request": tool_request,
        }

        result = await service._execute_tools(state)

        assert "tool_result" in result
        assert result["tool_result"].status == ToolStatus.SUCCESS
```

**Step 2: Run test to verify it fails**

Run: `cd backend && python -m pytest tests/test_orchestrator_service.py::TestExecuteTools -v`
Expected: FAIL with NotImplementedError

**Step 3: Implement _execute_tools**

Add import at top:

```python
from qualityfoundry.tools.registry import ToolNotFoundError
from datetime import datetime, timezone
```

Replace the method:

```python
    async def _execute_tools(self, state: OrchestrationState) -> OrchestrationState:
        """Node 3: Execute tool and collect result."""
        tool_request = state["tool_request"]

        try:
            tool_func = self.registry.get(tool_request.tool_name)
            state["tool_result"] = await tool_func(tool_request)
        except ToolNotFoundError:
            now = datetime.now(timezone.utc)
            state["tool_result"] = ToolResult(
                status=ToolStatus.FAILED,
                stdout=None,
                stderr=f"Tool not found: {tool_request.tool_name}",
                started_at=now,
                ended_at=now,
            )

        return state
```

**Step 4: Run test to verify it passes**

Run: `cd backend && python -m pytest tests/test_orchestrator_service.py::TestExecuteTools -v`
Expected: PASS

**Step 5: Write the failing test for _collect_evidence**

Add to `test_orchestrator_service.py`:

```python
from pathlib import Path
from qualityfoundry.governance.tracing.collector import TraceCollector


class TestCollectEvidence:
    """Tests for _collect_evidence node."""

    def test_collect_creates_evidence(self, tmp_path):
        """_collect_evidence should create evidence dict and save path."""
        db = MagicMock()

        # Create a real collector factory that uses tmp_path
        def test_collector_factory(run_id, input_nl, environment):
            return TraceCollector(
                run_id=str(run_id),
                input_nl=input_nl,
                environment=environment,
                artifact_root=tmp_path,
            )

        service = OrchestratorService(db, collector_factory=test_collector_factory)

        run_id = uuid4()
        inp = OrchestrationInput(
            nl_input="test input",
            environment_id=None,
            tool_name="run_pytest",
            tool_args={},
            timeout_s=60,
            dry_run=False,
        )
        tool_result = ToolResult(status=ToolStatus.SUCCESS, stdout="ok", stderr=None)

        state: OrchestrationState = {
            "run_id": run_id,
            "input": inp,
            "tool_request": ToolRequest(
                tool_name="run_pytest", args={}, run_id=run_id, timeout_s=60
            ),
            "tool_result": tool_result,
        }

        result = service._collect_evidence(state)

        assert "evidence" in result
        assert result["evidence"]["run_id"] == str(run_id)
        assert "report_path" in result
        assert result["report_path"].exists()
```

**Step 6: Run test to verify it fails**

Run: `cd backend && python -m pytest tests/test_orchestrator_service.py::TestCollectEvidence -v`
Expected: FAIL with NotImplementedError

**Step 7: Implement _collect_evidence**

Replace the method:

```python
    def _collect_evidence(self, state: OrchestrationState) -> OrchestrationState:
        """Node 4: Collect evidence and save to disk."""
        inp = state["input"]

        # Create collector via factory
        collector = self._collector_factory(
            state["run_id"],
            inp.nl_input,
            {"environment_id": str(inp.environment_id) if inp.environment_id else None},
        )

        # Add tool result
        collector.add_tool_result(state["tool_request"].tool_name, state["tool_result"])

        # Collect and save
        evidence = collector.collect()
        report_path = collector.save(evidence)

        state["evidence"] = evidence.model_dump()
        state["report_path"] = report_path

        return state
```

**Step 8: Run test to verify it passes**

Run: `cd backend && python -m pytest tests/test_orchestrator_service.py::TestCollectEvidence -v`
Expected: PASS

**Step 9: Commit**

```bash
git add backend/app/qualityfoundry/services/orchestrator_service.py backend/tests/test_orchestrator_service.py
git commit -m "feat(orchestrator): implement _execute_tools and _collect_evidence nodes

- _execute_tools: executes via registry, handles tool-not-found
- _collect_evidence: uses collector factory, saves evidence.json"
```

---

## Task 6: Implement _gate_and_hitl

**Files:**
- Modify: `backend/app/qualityfoundry/services/orchestrator_service.py`
- Modify: `backend/tests/test_orchestrator_service.py`

**Step 1: Write the failing test**

Add to `test_orchestrator_service.py`:

```python
from qualityfoundry.governance import GateDecision


class TestGateAndHitl:
    """Tests for _gate_and_hitl node."""

    def test_gate_pass_on_success(self, tmp_path):
        """Gate should PASS when tests pass."""
        db = MagicMock()
        service = OrchestratorService(db)

        # Evidence with passing tests
        evidence = {
            "run_id": str(uuid4()),
            "input_nl": "run tests",
            "environment": {},
            "tool_calls": [{"tool_name": "run_pytest", "status": "success"}],
            "artifacts": [],
            "summary": {"tests": 5, "failures": 0, "errors": 0, "skipped": 0, "time": 1.0, "passed": 5},
            "repro": None,
            "collected_at": "2024-01-01T00:00:00Z",
        }

        state: OrchestrationState = {
            "run_id": uuid4(),
            "evidence": evidence,
        }

        result = service._gate_and_hitl(state)

        assert result["decision"] == GateDecision.PASS
        assert "reason" in result
        assert result["approval_id"] is None

    def test_gate_fail_on_test_failures(self, tmp_path):
        """Gate should FAIL when tests fail."""
        db = MagicMock()
        service = OrchestratorService(db)

        evidence = {
            "run_id": str(uuid4()),
            "input_nl": "run tests",
            "environment": {},
            "tool_calls": [{"tool_name": "run_pytest", "status": "success"}],
            "artifacts": [],
            "summary": {"tests": 5, "failures": 2, "errors": 0, "skipped": 0, "time": 1.0, "passed": 3},
            "repro": None,
            "collected_at": "2024-01-01T00:00:00Z",
        }

        state: OrchestrationState = {"run_id": uuid4(), "evidence": evidence}

        result = service._gate_and_hitl(state)

        assert result["decision"] == GateDecision.FAIL

    def test_gate_hitl_on_high_risk_keyword(self):
        """Gate should NEED_HITL when high-risk keyword in input."""
        db = MagicMock()
        service = OrchestratorService(db)

        evidence = {
            "run_id": str(uuid4()),
            "input_nl": "deploy to production",  # high-risk keyword
            "environment": {},
            "tool_calls": [{"tool_name": "run_pytest", "status": "success"}],
            "artifacts": [],
            "summary": {"tests": 5, "failures": 0, "errors": 0, "skipped": 0, "time": 1.0, "passed": 5},
            "repro": None,
            "collected_at": "2024-01-01T00:00:00Z",
        }

        state: OrchestrationState = {"run_id": uuid4(), "evidence": evidence}

        result = service._gate_and_hitl(state)

        assert result["decision"] == GateDecision.NEED_HITL
```

**Step 2: Run test to verify it fails**

Run: `cd backend && python -m pytest tests/test_orchestrator_service.py::TestGateAndHitl -v`
Expected: FAIL with NotImplementedError

**Step 3: Implement _gate_and_hitl**

Add import at top:

```python
from qualityfoundry.governance.tracing.collector import Evidence
from qualityfoundry.governance.gate import evaluate_gate
```

Replace the method:

```python
    def _gate_and_hitl(self, state: OrchestrationState) -> OrchestrationState:
        """Node 5: Evaluate gate and create approval if needed."""
        # Reconstruct Evidence from dict
        evidence = Evidence.model_validate(state["evidence"])

        # Get policy if loaded, otherwise use default
        policy = state.get("policy")

        # Evaluate gate
        gate_result = evaluate_gate(evidence, policy)

        state["decision"] = gate_result.decision
        state["reason"] = gate_result.reason

        # Create approval if NEED_HITL
        if gate_result.decision == GateDecision.NEED_HITL:
            try:
                approval = self._approval_service.create_approval(
                    entity_type="orchestration",
                    entity_id=state["run_id"],
                    reviewer=None,
                )
                state["approval_id"] = approval.id
            except Exception:
                # Approval creation failure doesn't block main flow
                state["approval_id"] = None
        else:
            state["approval_id"] = None

        return state
```

**Step 4: Run test to verify it passes**

Run: `cd backend && python -m pytest tests/test_orchestrator_service.py::TestGateAndHitl -v`
Expected: PASS (3 tests)

**Step 5: Commit**

```bash
git add backend/app/qualityfoundry/services/orchestrator_service.py backend/tests/test_orchestrator_service.py
git commit -m "feat(orchestrator): implement _gate_and_hitl node

- Evaluates gate using policy
- Creates approval for NEED_HITL decisions
- Handles approval creation failures gracefully"
```

---

## Task 7: Implement run() Method

**Files:**
- Modify: `backend/app/qualityfoundry/services/orchestrator_service.py`
- Modify: `backend/tests/test_orchestrator_service.py`

**Step 1: Write the failing integration test**

Add to `test_orchestrator_service.py`:

```python
class TestRun:
    """Integration tests for run() method."""

    @pytest.mark.asyncio
    async def test_run_full_pipeline_pass(self, tmp_path):
        """Full pipeline should return PASS for passing tests."""
        db = MagicMock()

        # Fake registry
        fake_registry = ToolRegistry()
        fake_result = ToolResult(
            status=ToolStatus.SUCCESS,
            stdout="All tests passed",
            stderr=None,
        )

        async def fake_pytest(req):
            return fake_result

        fake_registry.register("run_pytest", fake_pytest)

        # Fake collector factory
        def test_collector_factory(run_id, input_nl, environment):
            return TraceCollector(
                run_id=str(run_id),
                input_nl=input_nl,
                environment=environment,
                artifact_root=tmp_path,
            )

        # Fake policy
        fake_policy = PolicyConfig(version="test", high_risk_keywords=[])

        service = OrchestratorService(
            db,
            registry=fake_registry,
            collector_factory=test_collector_factory,
            policy_loader=lambda: fake_policy,
        )

        req = OrchestrationRequest(
            nl_input="run tests",
            options=OrchestrationOptions(
                tool_name="run_pytest",
                args={"test_path": "tests"},
            ),
        )

        result = await service.run(req)

        assert isinstance(result, OrchestrationResult)
        assert result.decision == GateDecision.PASS
        assert result.report_path is not None
        assert result.report_path.exists()

    @pytest.mark.asyncio
    async def test_run_returns_hitl_for_high_risk(self, tmp_path):
        """Pipeline should return NEED_HITL for high-risk input."""
        db = MagicMock()

        fake_registry = ToolRegistry()
        async def fake_pytest(req):
            return ToolResult(status=ToolStatus.SUCCESS, stdout="ok", stderr=None)
        fake_registry.register("run_pytest", fake_pytest)

        def test_collector_factory(run_id, input_nl, environment):
            return TraceCollector(
                run_id=str(run_id),
                input_nl=input_nl,
                environment=environment,
                artifact_root=tmp_path,
            )

        # Policy with production as high-risk
        fake_policy = PolicyConfig(
            version="test",
            high_risk_keywords=["production"],
        )

        service = OrchestratorService(
            db,
            registry=fake_registry,
            collector_factory=test_collector_factory,
            policy_loader=lambda: fake_policy,
        )

        req = OrchestrationRequest(
            nl_input="deploy to production",
            options=OrchestrationOptions(tool_name="run_pytest", args={}),
        )

        result = await service.run(req)

        assert result.decision == GateDecision.NEED_HITL
```

**Step 2: Run test to verify it fails**

Run: `cd backend && python -m pytest tests/test_orchestrator_service.py::TestRun -v`
Expected: FAIL with NotImplementedError

**Step 3: Implement run()**

Replace the method:

```python
    async def run(self, req: OrchestrationRequest) -> OrchestrationResult:
        """Execute orchestration pipeline.

        Pipeline: normalize â†’ load_policy â†’ plan â†’ execute â†’ collect â†’ gate
        """
        from uuid import uuid4

        # Initialize state
        run_id = uuid4()
        state: OrchestrationState = {
            "run_id": run_id,
            "input": self._normalize_input(req),
        }

        # Execute pipeline
        state = self._load_policy(state)
        state = self._plan_tool_request(state)
        state = await self._execute_tools(state)
        state = self._collect_evidence(state)
        state = self._gate_and_hitl(state)

        # Build result
        return OrchestrationResult(
            run_id=run_id,
            decision=state["decision"],
            reason=state["reason"],
            evidence=state["evidence"],
            execution_id=None,  # Extensible: link to execution record
            approval_id=state.get("approval_id"),
            report_path=state.get("report_path"),
        )
```

**Step 4: Run test to verify it passes**

Run: `cd backend && python -m pytest tests/test_orchestrator_service.py::TestRun -v`
Expected: PASS (2 tests)

**Step 5: Commit**

```bash
git add backend/app/qualityfoundry/services/orchestrator_service.py backend/tests/test_orchestrator_service.py
git commit -m "feat(orchestrator): implement run() pipeline

- Executes all 5 nodes sequentially
- Returns OrchestrationResult domain object
- Full pipeline tested with mock dependencies"
```

---

## Task 8: Slim Down Routes

**Files:**
- Modify: `backend/app/qualityfoundry/api/v1/routes_orchestrations.py`

**Step 1: Verify existing smoke tests pass**

Run: `cd backend && python -m pytest tests/test_smoke_orchestration.py -v`
Expected: All PASS (this is our regression baseline)

**Step 2: Refactor routes to use service**

Replace the entire `run_orchestration` function and remove helper functions:

```python
"""QualityFoundry - Orchestration API Routes (PR-4)

ç¼–æŽ’æ‰§è¡Œ APIï¼šç»Ÿä¸€çš„æµ‹è¯•æ‰§è¡Œå…¥å£ï¼Œé›†æˆå·¥å…·å±‚ã€è¯æ®é“¾å’Œé—¨ç¦å†³ç­–ã€‚

POST /api/v1/orchestrations/run
- æŽ¥æ”¶è‡ªç„¶è¯­è¨€è¾“å…¥æˆ–ç»“æž„åŒ–é€‰é¡¹
- å§”æ‰˜ç»™ OrchestratorService æ‰§è¡Œ
- è¿”å›žå†³ç­–ã€è¯æ®å’Œé“¾æŽ¥
"""

from __future__ import annotations

from typing import Any, Optional
from uuid import UUID

from fastapi import APIRouter, Depends
from pydantic import BaseModel, Field
from sqlalchemy.orm import Session

from qualityfoundry.database.config import get_db
from qualityfoundry.governance import GateDecision
from qualityfoundry.services.orchestrator_service import OrchestratorService, OrchestrationResult

router = APIRouter(prefix="/orchestrations", tags=["orchestrations"])


# ============== Request/Response Models ==============


class OrchestrationOptions(BaseModel):
    """æ‰§è¡Œé€‰é¡¹ï¼ˆå¯æŽ§æ¨¡å¼ï¼Œç”¨äºŽ smoke æµ‹è¯•ï¼‰"""

    tool_name: str = Field(default="run_pytest", description="è¦æ‰§è¡Œçš„å·¥å…·åç§°")
    args: dict[str, Any] = Field(default_factory=dict, description="å·¥å…·å‚æ•°")
    timeout_s: int = Field(default=120, ge=1, le=3600, description="è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰")
    dry_run: bool = Field(default=False, description="æ˜¯å¦ä¸ºå¹²è¿è¡Œæ¨¡å¼")


class OrchestrationRequest(BaseModel):
    """ç¼–æŽ’æ‰§è¡Œè¯·æ±‚"""

    nl_input: str = Field(..., description="è‡ªç„¶è¯­è¨€è¾“å…¥æè¿°")
    environment_id: Optional[UUID] = Field(default=None, description="çŽ¯å¢ƒ ID")
    options: Optional[OrchestrationOptions] = Field(
        default=None,
        description="æ‰§è¡Œé€‰é¡¹ï¼ˆä¼˜å…ˆäºŽ NL è§£æžï¼Œç”¨äºŽç¡®å®šæ€§æµ‹è¯•ï¼‰",
    )


class OrchestrationLinks(BaseModel):
    """æ‰§è¡Œç»“æžœé“¾æŽ¥"""

    execution_id: Optional[UUID] = Field(default=None, description="æ‰§è¡Œè®°å½• ID")
    approval_id: Optional[UUID] = Field(default=None, description="å®¡æ‰¹è®°å½• IDï¼ˆNEED_HITL æ—¶ï¼‰")
    report_url: Optional[str] = Field(default=None, description="è¯æ®æŠ¥å‘Šä¸‹è½½ URL")


class OrchestrationResponse(BaseModel):
    """ç¼–æŽ’æ‰§è¡Œå“åº”"""

    run_id: UUID = Field(..., description="è¿è¡Œ ID")
    decision: GateDecision = Field(..., description="é—¨ç¦å†³ç­–")
    reason: str = Field(..., description="å†³ç­–åŽŸå› ")
    evidence: dict[str, Any] = Field(..., description="è¯æ®æ‘˜è¦")
    links: OrchestrationLinks = Field(..., description="ç›¸å…³é“¾æŽ¥")


# ============== Helper Functions ==============


def _build_response(result: OrchestrationResult) -> OrchestrationResponse:
    """Convert domain result to HTTP response."""
    report_url = None
    if result.report_path:
        report_url = f"/api/v1/artifacts/{result.run_id}/evidence.json"

    return OrchestrationResponse(
        run_id=result.run_id,
        decision=result.decision,
        reason=result.reason,
        evidence=result.evidence,
        links=OrchestrationLinks(
            execution_id=result.execution_id,
            approval_id=result.approval_id,
            report_url=report_url,
        ),
    )


# ============== API Endpoints ==============


@router.post("/run", response_model=OrchestrationResponse)
async def run_orchestration(
    req: OrchestrationRequest,
    db: Session = Depends(get_db),
):
    """
    æ‰§è¡Œç¼–æŽ’æµç¨‹ã€‚

    å§”æ‰˜ç»™ OrchestratorService æ‰§è¡Œå®Œæ•´ç®¡é“ï¼š
    load_policy â†’ plan â†’ execute â†’ collect â†’ gate
    """
    service = OrchestratorService(db)
    result = await service.run(req)
    return _build_response(result)
```

**Step 3: Run smoke tests to verify no regression**

Run: `cd backend && python -m pytest tests/test_smoke_orchestration.py -v`
Expected: All PASS

**Step 4: Commit**

```bash
git add backend/app/qualityfoundry/api/v1/routes_orchestrations.py
git commit -m "refactor(routes): slim down orchestrations route to use service

- Remove inline business logic
- Remove helper functions (_build_tool_request, _execute_tool, _create_approval_if_needed)
- Delegate to OrchestratorService.run()
- Route only handles DTOâ†’domainâ†’response conversion"
```

---

## Task 9: Fix Import Cycle and Run Full Test Suite

**Files:**
- Modify: `backend/app/qualityfoundry/services/orchestrator_service.py`

**Step 1: Move DTOs to avoid circular import**

The service imports `OrchestrationRequest` from routes, but routes imports from service. Fix by using a protocol or moving DTOs.

Update the service to accept a protocol instead:

```python
# At top of orchestrator_service.py, replace the import
from typing import Protocol

class OrchestrationRequestProtocol(Protocol):
    """Protocol for orchestration request (avoids circular import)."""
    nl_input: str
    environment_id: UUID | None
    options: Any  # OrchestrationOptions or None
```

Then update `_normalize_input` signature:

```python
    def _normalize_input(self, req: OrchestrationRequestProtocol) -> OrchestrationInput:
```

**Step 2: Run full test suite**

Run: `cd backend && python -m pytest -v`
Expected: All tests PASS

**Step 3: Run regression**

Run: `cd backend && python -m qualityfoundry.governance.evals --fail-on-regression`
Expected: diff=0 (no regressions)

**Step 4: Commit**

```bash
git add backend/app/qualityfoundry/services/orchestrator_service.py
git commit -m "fix(orchestrator): resolve import cycle with Protocol

- Use OrchestrationRequestProtocol instead of concrete import
- Allows service to be imported independently of routes"
```

---

## Task 10: Final Verification and PR

**Step 1: Run all checks**

```bash
cd backend
ruff check .
python -m pytest -v
python -m pytest -m smoke -v
python -m qualityfoundry.governance.evals --fail-on-regression
```

Expected: All pass, diff=0

**Step 2: Create PR**

```bash
git push -u origin vk/2b8f-check
gh pr create --title "feat: Phase 1.2 - Extract OrchestratorService (L2 Layer)" --body "$(cat <<'EOF'
## Summary
- Extract business logic from `routes_orchestrations.py` into `OrchestratorService`
- Define LangGraph-ready node boundaries (5 nodes: load_policy, plan, execute, collect, gate)
- Mixed dependency injection for testability (DB required, registry/collector/policy optional)
- Domain types: `OrchestrationResult`, `OrchestrationState`, `OrchestrationInput`

## Changes
- **New**: `services/orchestrator_service.py` - Service with 5 node methods
- **New**: `tests/test_orchestrator_service.py` - Unit tests for all nodes
- **Modified**: `api/v1/routes_orchestrations.py` - Slim route, delegates to service

## Verification
- [x] All existing smoke tests pass
- [x] Regression diff = 0
- [x] New service unit tests pass
- [x] Ruff lint clean

## Next Steps
- Phase 2.2: Replace linear pipeline with LangGraph state machine
- Phase 5.1: Add cost governance enforcement in execute node

ðŸ¤– Generated with [Claude Code](https://claude.com/claude-code)
EOF
)"
```

---

## Summary

| Task | Description | Files |
|------|-------------|-------|
| 1 | Define domain types | `orchestrator_service.py` |
| 2 | Service skeleton | `orchestrator_service.py` |
| 3 | `_normalize_input` | `orchestrator_service.py`, `test_orchestrator_service.py` |
| 4 | `_load_policy`, `_plan_tool_request` | `orchestrator_service.py`, `test_orchestrator_service.py` |
| 5 | `_execute_tools`, `_collect_evidence` | `orchestrator_service.py`, `test_orchestrator_service.py` |
| 6 | `_gate_and_hitl` | `orchestrator_service.py`, `test_orchestrator_service.py` |
| 7 | `run()` method | `orchestrator_service.py`, `test_orchestrator_service.py` |
| 8 | Slim routes | `routes_orchestrations.py` |
| 9 | Fix import cycle | `orchestrator_service.py` |
| 10 | Final verification + PR | - |
