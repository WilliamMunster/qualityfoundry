# Phase 2.2: LangGraph Integration Implementation Plan

> **For Claude:** REQUIRED SUB-SKILL: Use superpowers:executing-plans to implement this plan task-by-task.

**Goal:** Replace the linear OrchestratorService pipeline with a LangGraph state machine to enable dynamic control flow, conditional branching, and future extensibility.

**Architecture:** Wrap existing node methods (`_load_policy`, `_plan_tool_request`, `_execute_tools`, `_collect_evidence`, `_gate_and_hitl`) as LangGraph nodes. Create a StateGraph with explicit edges. Preserve all existing behavior and tests while enabling future dynamic routing.

**Tech Stack:** LangGraph 0.2+, Python 3.11+, existing OrchestratorService infrastructure

---

## Prerequisites

- All existing tests pass: `pytest backend/tests/test_orchestrator_service.py -v`
- Main branch is clean and up-to-date

---

## Task 1: Add LangGraph Dependency

**Files:**
- Modify: `backend/pyproject.toml`

**Step 1: Add langgraph to dependencies**

Edit `backend/pyproject.toml`, add to `dependencies` array:

```toml
"langgraph>=0.2.0",
```

**Step 2: Install and verify**

Run:
```bash
cd backend && pip install -e .
```

Expected: Installation succeeds without errors

**Step 3: Verify import works**

Run:
```bash
python -c "from langgraph.graph import StateGraph; print('LangGraph OK')"
```

Expected: `LangGraph OK`

**Step 4: Commit**

```bash
git add backend/pyproject.toml
git commit -m "chore: add langgraph dependency for Phase 2.2"
```

---

## Task 2: Create LangGraph State Type

**Files:**
- Modify: `backend/app/qualityfoundry/services/orchestrator_service.py`
- Test: `backend/tests/test_orchestrator_service.py`

**Step 1: Write failing test for LangGraphState type**

Add to `backend/tests/test_orchestrator_service.py`:

```python
class TestLangGraphState:
    """Tests for LangGraph state compatibility."""

    def test_langgraph_state_has_required_annotations(self):
        """LangGraphState should have all required field annotations for LangGraph."""
        from qualityfoundry.services.orchestrator_service import LangGraphState
        from typing import get_type_hints

        hints = get_type_hints(LangGraphState)

        # Required fields
        assert "run_id" in hints
        assert "input" in hints
        assert "policy" in hints
        assert "tool_request" in hints
        assert "tool_result" in hints
        assert "evidence" in hints
        assert "decision" in hints
        assert "reason" in hints
```

**Step 2: Run test to verify it fails**

Run: `pytest backend/tests/test_orchestrator_service.py::TestLangGraphState::test_langgraph_state_has_required_annotations -v`

Expected: FAIL with "cannot import name 'LangGraphState'"

**Step 3: Implement LangGraphState**

Add to `backend/app/qualityfoundry/services/orchestrator_service.py` after `OrchestrationState`:

```python
from typing import Annotated
from operator import add

class LangGraphState(TypedDict, total=False):
    """State for LangGraph workflow.

    This replaces OrchestrationState for LangGraph compatibility.
    All fields are optional (total=False) to allow incremental building.
    """
    run_id: UUID
    input: OrchestrationInput
    policy: PolicyConfig
    policy_meta: dict[str, Any]
    tool_request: ToolRequest
    tool_result: ToolResult
    evidence: dict[str, Any]
    decision: GateDecision
    reason: str
    approval_id: UUID | None
    report_path: Path | None
    # For future: message history accumulation
    messages: Annotated[list[str], add]
```

**Step 4: Run test to verify it passes**

Run: `pytest backend/tests/test_orchestrator_service.py::TestLangGraphState -v`

Expected: PASS

**Step 5: Commit**

```bash
git add backend/app/qualityfoundry/services/orchestrator_service.py backend/tests/test_orchestrator_service.py
git commit -m "feat(orchestrator): add LangGraphState type definition"
```

---

## Task 3: Create Graph Builder Function

**Files:**
- Modify: `backend/app/qualityfoundry/services/orchestrator_service.py`
- Test: `backend/tests/test_orchestrator_service.py`

**Step 1: Write failing test for graph builder**

Add to `backend/tests/test_orchestrator_service.py`:

```python
class TestGraphBuilder:
    """Tests for LangGraph graph construction."""

    def test_build_graph_returns_compiled_graph(self):
        """build_orchestration_graph should return a compiled StateGraph."""
        from langgraph.graph import CompiledGraph
        from qualityfoundry.services.orchestrator_service import build_orchestration_graph, OrchestratorService
        from unittest.mock import MagicMock

        db = MagicMock()
        service = OrchestratorService(db)

        graph = build_orchestration_graph(service)

        assert isinstance(graph, CompiledGraph)

    def test_build_graph_has_expected_nodes(self):
        """build_orchestration_graph should include all 5 node steps."""
        from qualityfoundry.services.orchestrator_service import build_orchestration_graph, OrchestratorService
        from unittest.mock import MagicMock

        db = MagicMock()
        service = OrchestratorService(db)

        graph = build_orchestration_graph(service)

        # Check nodes exist (LangGraph exposes nodes via .nodes)
        node_names = set(graph.nodes.keys())
        expected_nodes = {"load_policy", "plan_tool_request", "execute_tools", "collect_evidence", "gate_and_hitl"}

        assert expected_nodes.issubset(node_names)
```

**Step 2: Run test to verify it fails**

Run: `pytest backend/tests/test_orchestrator_service.py::TestGraphBuilder -v`

Expected: FAIL with "cannot import name 'build_orchestration_graph'"

**Step 3: Implement build_orchestration_graph**

Add to `backend/app/qualityfoundry/services/orchestrator_service.py`:

```python
from langgraph.graph import StateGraph, END


def build_orchestration_graph(service: OrchestratorService):
    """Build LangGraph state machine for orchestration.

    Nodes:
    1. load_policy: Load policy configuration
    2. plan_tool_request: Build tool request from input
    3. execute_tools: Execute tool and get result
    4. collect_evidence: Collect and save evidence
    5. gate_and_hitl: Evaluate gate and create approval if needed

    Args:
        service: OrchestratorService instance with injected dependencies

    Returns:
        Compiled StateGraph ready for invocation
    """
    # Create graph with our state type
    graph = StateGraph(LangGraphState)

    # Add nodes - wrap service methods
    graph.add_node("load_policy", service._load_policy)
    graph.add_node("plan_tool_request", service._plan_tool_request)
    graph.add_node("execute_tools", service._execute_tools)
    graph.add_node("collect_evidence", service._collect_evidence)
    graph.add_node("gate_and_hitl", service._gate_and_hitl)

    # Define edges (linear flow for now, can add conditional routing later)
    graph.set_entry_point("load_policy")
    graph.add_edge("load_policy", "plan_tool_request")
    graph.add_edge("plan_tool_request", "execute_tools")
    graph.add_edge("execute_tools", "collect_evidence")
    graph.add_edge("collect_evidence", "gate_and_hitl")
    graph.add_edge("gate_and_hitl", END)

    # Compile and return
    return graph.compile()
```

**Step 4: Run test to verify it passes**

Run: `pytest backend/tests/test_orchestrator_service.py::TestGraphBuilder -v`

Expected: PASS

**Step 5: Commit**

```bash
git add backend/app/qualityfoundry/services/orchestrator_service.py backend/tests/test_orchestrator_service.py
git commit -m "feat(orchestrator): add build_orchestration_graph function"
```

---

## Task 4: Add Graph-Based Run Method

**Files:**
- Modify: `backend/app/qualityfoundry/services/orchestrator_service.py`
- Test: `backend/tests/test_orchestrator_service.py`

**Step 1: Write failing test for graph-based run**

Add to `backend/tests/test_orchestrator_service.py`:

```python
class TestRunWithGraph:
    """Tests for run_with_graph method."""

    @pytest.mark.asyncio
    async def test_run_with_graph_returns_same_result_as_run(self):
        """run_with_graph should produce identical results to run."""
        from qualityfoundry.governance import GateDecision
        from qualityfoundry.governance.gate import GateResult
        from qualityfoundry.services.orchestrator_service import OrchestrationResult
        from unittest.mock import MagicMock, AsyncMock

        db = MagicMock()

        # Mock all dependencies (same as TestRun)
        mock_policy = PolicyConfig()
        mock_policy_loader = MagicMock(return_value=mock_policy)

        mock_tool_result = ToolResult.success(stdout="All tests passed")
        mock_registry = MagicMock()
        mock_registry.execute = AsyncMock(return_value=mock_tool_result)

        mock_evidence = MagicMock()
        mock_evidence.model_dump.return_value = {"run_id": "test", "input_nl": "run tests", "tool_calls": []}
        mock_collector = MagicMock()
        mock_collector.collect.return_value = mock_evidence
        mock_collector.save.return_value = "/path/to/evidence.json"
        mock_collector_factory = MagicMock(return_value=mock_collector)

        mock_gate_result = GateResult(
            decision=GateDecision.PASS,
            reason="All tests passed",
        )
        mock_gate_evaluator = MagicMock(return_value=mock_gate_result)

        service = OrchestratorService(
            db,
            registry=mock_registry,
            policy_loader=mock_policy_loader,
            collector_factory=mock_collector_factory,
            gate_evaluator=mock_gate_evaluator,
        )
        service._approval_service = MagicMock()

        req = OrchestrationRequest(
            nl_input="run tests",
            environment_id=None,
            options=None,
        )

        # Run both methods
        result_legacy = await service.run(req)

        # Reset mocks for second run
        mock_policy_loader.reset_mock()
        mock_registry.execute.reset_mock()
        mock_collector.add_tool_result.reset_mock()
        mock_gate_evaluator.reset_mock()

        result_graph = await service.run_with_graph(req)

        # Results should be equivalent (except run_id which is generated fresh)
        assert result_graph.decision == result_legacy.decision
        assert result_graph.reason == result_legacy.reason
```

**Step 2: Run test to verify it fails**

Run: `pytest backend/tests/test_orchestrator_service.py::TestRunWithGraph -v`

Expected: FAIL with "OrchestratorService has no attribute 'run_with_graph'"

**Step 3: Implement run_with_graph method**

Add to `OrchestratorService` class in `backend/app/qualityfoundry/services/orchestrator_service.py`:

```python
    async def run_with_graph(self, req: OrchestrationRequestProtocol) -> OrchestrationResult:
        """Execute orchestration using LangGraph state machine.

        This is the LangGraph-powered version of run().
        Behavior should be identical to run() but uses StateGraph for execution.

        Returns:
            OrchestrationResult with decision, reason, evidence, and optional approval_id
        """
        from uuid import uuid4

        # Generate run_id
        run_id = uuid4()

        # Normalize input
        normalized_input = self._normalize_input(req)

        # Build initial state
        initial_state: LangGraphState = {
            "run_id": run_id,
            "input": normalized_input,
            "messages": [],
        }

        # Build and run graph
        graph = build_orchestration_graph(self)

        # LangGraph invoke - handles async nodes automatically
        final_state = await graph.ainvoke(initial_state)

        # Build result from final state
        return OrchestrationResult(
            run_id=run_id,
            decision=final_state["decision"],
            reason=final_state["reason"],
            evidence=final_state["evidence"],
            approval_id=final_state.get("approval_id"),
            report_path=final_state.get("report_path"),
        )
```

**Step 4: Run test to verify it passes**

Run: `pytest backend/tests/test_orchestrator_service.py::TestRunWithGraph -v`

Expected: PASS

**Step 5: Commit**

```bash
git add backend/app/qualityfoundry/services/orchestrator_service.py backend/tests/test_orchestrator_service.py
git commit -m "feat(orchestrator): add run_with_graph method using LangGraph"
```

---

## Task 5: Migrate Default Run to Use Graph

**Files:**
- Modify: `backend/app/qualityfoundry/services/orchestrator_service.py`
- Test: `backend/tests/test_orchestrator_service.py`

**Step 1: Write test to ensure backward compatibility**

Add to `backend/tests/test_orchestrator_service.py`:

```python
class TestBackwardCompatibility:
    """Tests to ensure existing API remains unchanged."""

    @pytest.mark.asyncio
    async def test_run_still_works_after_migration(self):
        """Existing run() method should work identically after migration."""
        from qualityfoundry.governance import GateDecision
        from qualityfoundry.governance.gate import GateResult
        from unittest.mock import MagicMock, AsyncMock

        db = MagicMock()

        mock_policy = PolicyConfig()
        mock_policy_loader = MagicMock(return_value=mock_policy)

        mock_tool_result = ToolResult.success(stdout="OK")
        mock_registry = MagicMock()
        mock_registry.execute = AsyncMock(return_value=mock_tool_result)

        mock_evidence = MagicMock()
        mock_evidence.model_dump.return_value = {"run_id": "test", "input_nl": "test", "tool_calls": []}
        mock_collector = MagicMock()
        mock_collector.collect.return_value = mock_evidence
        mock_collector.save.return_value = "/tmp/evidence.json"
        mock_collector_factory = MagicMock(return_value=mock_collector)

        mock_gate_result = GateResult(decision=GateDecision.PASS, reason="OK")
        mock_gate_evaluator = MagicMock(return_value=mock_gate_result)

        service = OrchestratorService(
            db,
            registry=mock_registry,
            policy_loader=mock_policy_loader,
            collector_factory=mock_collector_factory,
            gate_evaluator=mock_gate_evaluator,
        )
        service._approval_service = MagicMock()

        req = OrchestrationRequest(
            nl_input="run tests",
            environment_id=None,
            options=None,
        )

        result = await service.run(req)

        # All existing assertions should still pass
        assert result.decision == GateDecision.PASS
        assert result.reason == "OK"
        mock_policy_loader.assert_called()
        mock_registry.execute.assert_called()
```

**Step 2: Run test to verify it passes (before migration)**

Run: `pytest backend/tests/test_orchestrator_service.py::TestBackwardCompatibility -v`

Expected: PASS

**Step 3: Migrate run() to use graph internally**

Replace the `run` method in `OrchestratorService`:

```python
    async def run(self, req: OrchestrationRequestProtocol) -> OrchestrationResult:
        """Execute orchestration pipeline using LangGraph.

        Pipeline: normalize â†’ load_policy â†’ plan â†’ execute â†’ collect â†’ gate

        This method now uses LangGraph internally for execution,
        enabling future dynamic routing and conditional branching.

        Returns:
            OrchestrationResult with decision, reason, evidence, and optional approval_id
        """
        # Delegate to graph-based implementation
        return await self.run_with_graph(req)
```

**Step 4: Run ALL existing tests to verify backward compatibility**

Run: `pytest backend/tests/test_orchestrator_service.py -v`

Expected: ALL PASS

**Step 5: Commit**

```bash
git add backend/app/qualityfoundry/services/orchestrator_service.py backend/tests/test_orchestrator_service.py
git commit -m "refactor(orchestrator): migrate run() to use LangGraph internally"
```

---

## Task 6: Run Regression Tests

**Files:**
- None (validation only)

**Step 1: Run smoke tests**

Run:
```bash
cd backend && pytest -m smoke -v
```

Expected: ALL PASS

**Step 2: Run regression evaluation**

Run:
```bash
cd backend && python -m qualityfoundry.governance.evals
```

Expected: 5/5 passed, no regressions

**Step 3: Run full test suite**

Run:
```bash
cd backend && pytest tests/ -v --tb=short
```

Expected: ALL PASS

**Step 4: Commit verification note**

```bash
git add .
git commit -m "test: verify Phase 2.2 LangGraph integration passes all tests" --allow-empty
```

---

## Task 7: Update Documentation

**Files:**
- Modify: `docs/status/progress_baseline.md`
- Modify: `README.md`

**Step 1: Update progress baseline**

Edit `docs/status/progress_baseline.md`, change L2 status:

From:
```markdown
| **L2** | Orchestration (ç¼–æ’å±‚) | âœ… Phase 1.2 Complete (LangGraph-ready nodes) |
```

To:
```markdown
| **L2** | Orchestration (ç¼–æ’å±‚) | âœ… Phase 2.2 Complete (LangGraph state machine) |
```

And update Phase table:

```markdown
| **Phase 2.2** | LangGraph Integration | `from langgraph.graph import StateGraph` in orchestrator_service.py | âœ… |
```

Move from "Not Started" to "Merged to Main":
```markdown
| **Phase 2.2** | LangGraph state machine | `build_orchestration_graph()` in orchestrator_service.py | âœ… |
```

**Step 2: Update README architecture table**

Edit `README.md`, update L2 status:

From:
```markdown
| **L2** | Orchestration (ç¼–æ’å±‚) | âœ… Phase 1.2 Complete (LangGraph-ready nodes) |
```

To:
```markdown
| **L2** | Orchestration (ç¼–æ’å±‚) | âœ… Phase 2.2 Complete (LangGraph state machine) |
```

And update "Not Started" section, remove LangGraph:

```markdown
### Not Started
- ğŸ”´ **æˆæœ¬æ²»ç† (Phase 5.1)**ï¼šé¢„ç®—/è¶…æ—¶ç†”æ–­
- ğŸ”´ **å®¡è®¡æ—¥å¿—**ï¼šå®Œæ•´çš„æ“ä½œå®¡è®¡
```

**Step 3: Commit documentation**

```bash
git add docs/status/progress_baseline.md README.md
git commit -m "docs: update progress for Phase 2.2 LangGraph integration"
```

---

## Task 8: Final Verification and Tag

**Files:**
- None (validation and git operations only)

**Step 1: Run full validation**

Run:
```bash
cd backend && pytest tests/ -v && python -m qualityfoundry.governance.evals
```

Expected: ALL PASS, 5/5 regression cases pass

**Step 2: Create version tag**

```bash
git tag -a v0.11-langgraph -m "Phase 2.2: LangGraph state machine integration"
```

**Step 3: Summary**

Phase 2.2 complete. The orchestration layer now uses LangGraph for:
- State machine execution
- Explicit node boundaries
- Future-ready conditional routing

---

## Rollback Plan

If issues arise:

1. Revert run() to use linear pipeline (keep run_with_graph for testing)
2. All node methods remain unchanged - no business logic changes
3. Remove langgraph dependency if needed

---

## Future Enhancements (Phase 2.3+)

With LangGraph in place, future work can add:
- Conditional routing based on gate decision
- Retry loops with backoff
- Human-in-the-loop interrupt points
- Parallel tool execution
- Subgraph composition
